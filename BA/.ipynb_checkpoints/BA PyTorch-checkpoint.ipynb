{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import bz2\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import autograd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"http://grail.cs.washington.edu/projects/bal/data/ladybug/\"\n",
    "FILE_NAME = \"problem-49-7776-pre.txt.bz2\"\n",
    "URL = BASE_URL + FILE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(FILE_NAME):\n",
    "    urllib.request.urlretrieve(URL, FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bal_data(file_name):\n",
    "    with bz2.open(file_name, \"rt\") as file:\n",
    "        n_cameras, n_points, n_observations = map(int, file.readline().split())\n",
    "    \n",
    "        camera_indices = np.empty(n_observations, dtype = int)\n",
    "        point_indices = np.empty(n_observations, dtype = int)\n",
    "        points_2d = torch.empty(n_observations, 2, device = device)\n",
    "\n",
    "        for i in range(n_observations):\n",
    "            camera_index, point_index, x, y = file.readline().split()\n",
    "            camera_indices[i] = camera_index\n",
    "            point_indices[i] = point_index\n",
    "            points_2d[i] = torch.tensor([float(x), float(y)])\n",
    "\n",
    "            camera_params = torch.empty(n_cameras*9, device = device)\n",
    "\n",
    "        for i in range(n_cameras*9):\n",
    "            camera_params[i] = float(file.readline())\n",
    "\n",
    "        camera_params = camera_params.view(n_cameras, -1)\n",
    "\n",
    "        points_3d = torch.empty(n_points*3, device = device)\n",
    "\n",
    "        for i in range(n_points*3):\n",
    "            points_3d[i] = float(file.readline())\n",
    "        points_3d = points_3d.view(n_points, -1)\n",
    "            \n",
    "    return camera_params, points_3d, camera_indices, point_indices, points_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_params, p3d, camera_indices, point_indices, points_2d = read_bal_data(FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_indices = torch.tensor(camera_indices, device = device)\n",
    "point_indices = torch.tensor(point_indices, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_cameras: 49\n",
      "n_points: 7776\n",
      "Total number of parameters: 23769\n",
      "Total number of residuals: 63686\n"
     ]
    }
   ],
   "source": [
    "n_cameras = c_params.size()[0]\n",
    "n_points = p3d.size()[0]\n",
    "\n",
    "n = 9*n_cameras + 3*n_points\n",
    "m = 2*points_2d.size()[0]\n",
    "\n",
    "print(\"n_cameras: {}\".format(n_cameras))\n",
    "print(\"n_points: {}\".format(n_points))\n",
    "print(\"Total number of parameters: {}\".format(n))\n",
    "print(\"Total number of residuals: {}\".format(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6120,  0.5718, -1.8471],\n",
       "        [ 1.7075,  0.9539, -6.8772],\n",
       "        [-0.3734,  1.5359, -4.7824],\n",
       "        ...,\n",
       "        [-0.6642, -0.1351, -5.5425],\n",
       "        [-0.8193,  0.0765, -4.5143],\n",
       "        [-0.7480,  0.0371, -4.8132]], requires_grad=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_params.requires_grad_(True)\n",
    "p3d.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(points, rot_vecs):\n",
    "    \n",
    "    theta = torch.norm(rot_vecs, dim = 1, keepdim=True)\n",
    "    v = rot_vecs/theta\n",
    "#         v[v != v] = 0.\n",
    "#     print(v.size(), points.size())\n",
    "    \n",
    "    dot = torch.sum(points*v, dim = 1, keepdim = True)\n",
    "    \n",
    "    cos_theta = torch.cos(theta)\n",
    "    sin_theta = torch.sin(theta)\n",
    "    \n",
    "    ans = cos_theta*points + sin_theta*torch.cross(v, points) + dot*(1-cos_theta)*v\n",
    "    \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project(points, camera_params):\n",
    "    R = torch.index_select(camera_params, 1, torch.tensor([0,1,2]))\n",
    "    T = torch.index_select(camera_params, 1, torch.tensor([3,4,5]))\n",
    "    # print(R.size(), T.size())\n",
    "    points_proj = rotate(points, R)\n",
    "    points_proj = points_proj + T\n",
    "    denom = torch.index_select(points_proj,1,torch.tensor([2])).view(-1,1)\n",
    "    points_proj_2 = -torch.index_select(points_proj,1,torch.tensor([0,1]))/denom\n",
    "#     f = camera_params[:,6]\n",
    "#     k1 = camera_params[:,7]\n",
    "#     k2 = camera_params[:,8]\n",
    "    f = torch.index_select(camera_params, 1, torch.tensor([6]))\n",
    "    k1 = torch.index_select(camera_params, 1, torch.tensor([7]))\n",
    "    k2 = torch.index_select(camera_params, 1, torch.tensor([8]))\n",
    "    \n",
    "    n = torch.sum(torch.mul(points_proj_2,points_proj_2), dim = 1)\n",
    "    # print(f.size(), k1.size(), k2.size(), n.size())\n",
    "    r = 1 + torch.mul(n,k1.view(-1)) + torch.mul(k2.view(-1),torch.mul(n,n))\n",
    "    # print(r.size(), f.size(), points_proj.size())\n",
    "    # print(torch.mul(r,f.view(f.numel())).size())\n",
    "    points_proj_3 = points_proj_2*torch.mul(r,f.view(-1)).unsqueeze(1)\n",
    "    return points_proj_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(camera_params, points_3d, n_cameras, n_points, camera_indices, point_indices, points_2d):\n",
    "#     cp = params[:n_cameras*9].view(n_cameras, 9)\n",
    "#     p3d = params[n_cameras*9:].view(n_points, 3)\n",
    "#     points_proj = project(p3d[point_indices], cp[camera_indices])\n",
    "    points_3d_2 = torch.index_select(points_3d, 0, point_indices)\n",
    "    camera_params_2 = torch.index_select(camera_params, 0, camera_indices)\n",
    "    points_proj = project(points_3d_2, camera_params_2)\n",
    "    ans = points_proj - points_2d\n",
    "    return ans.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = fun(camera_params, points_3d, n_cameras, n_points, camera_indices, point_indices, points_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = fun(camera_params, points_3d, n_cameras, n_points, camera_indices, point_indices, points_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = f.pow(2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_3d = torch.index_select(p3d, 0, point_indices)\n",
    "camera_params = torch.index_select(c_params, 0, camera_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = torch.index_select(camera_params, 1, torch.tensor([0,1,2]))\n",
    "T = torch.index_select(camera_params, 1, torch.tensor([3,4,5]))\n",
    "theta = torch.norm(R, dim = 1, keepdim=True)\n",
    "v = R/theta\n",
    "dot = torch.sum(points_3d*v, dim = 1, keepdim = True)\n",
    "\n",
    "cos_theta = torch.cos(theta)\n",
    "sin_theta = torch.sin(theta)\n",
    "\n",
    "points_proj = cos_theta*points_3d + sin_theta*torch.cross(v, points_3d) + dot*(1-cos_theta)*v\n",
    "points_proj = points_proj + T\n",
    "denom = torch.index_select(points_proj,1,torch.tensor([2])).view(-1,1)\n",
    "points_proj = -torch.index_select(points_proj,1,torch.tensor([0,1]))/denom\n",
    "\n",
    "f = torch.index_select(camera_params, 1, torch.tensor([6]))\n",
    "k1 = torch.index_select(camera_params, 1, torch.tensor([7]))\n",
    "k2 = torch.index_select(camera_params, 1, torch.tensor([8]))\n",
    "\n",
    "n = torch.sum(torch.mul(points_proj,points_proj), dim = 1)\n",
    "r = 1 + torch.mul(n,k1.view(-1)) + torch.mul(k2.view(-1),torch.mul(n,n))\n",
    "points_proj = points_proj*torch.mul(r,f.view(-1)).unsqueeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = (points_proj - points_2d).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = f.pow(2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.6374e+04,  1.7635e+04,  3.0804e+04],\n",
      "        [ 1.0622e+03,  7.0126e+02,  5.4114e+02],\n",
      "        [-1.4381e+04,  3.6268e+04,  3.6153e+04],\n",
      "        ...,\n",
      "        [ 2.0478e-01, -1.0027e+01,  3.9044e-01],\n",
      "        [ 8.7769e-01,  6.0243e+00, -2.4398e-01],\n",
      "        [-1.1459e+00, -1.1489e+01,  2.0699e-01]])\n"
     ]
    }
   ],
   "source": [
    "print(p3d.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  -->  1701824.875\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    f = fun(c_params, p3d, n_cameras, n_points, camera_indices, point_indices, points_2d)\n",
    "    \n",
    "    loss = f.pow(2).sum()\n",
    "    \n",
    "    print(i, \" --> \", loss.item())\n",
    "    loss.backward()\n",
    "    \n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        print(c_params)\n",
    "        c_params -= lr*c_params.grad\n",
    "        p3d -= lr*p3d.grad\n",
    "        print(c_params)\n",
    "        c_params.grad.zero_()\n",
    "        p3d.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_params_copy = c_params.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.1000e+00, -4.9495e-01, -2.1131e-01,  4.2459e-01, -7.7444e-01,\n",
       "         -1.6059e+00,  3.9974e+02, -4.3441e+00, -6.1503e+00],\n",
       "        [-2.4602e+00, -8.6527e-01, -1.1094e-01,  4.9460e-01, -5.7304e-01,\n",
       "         -1.2086e+00,  4.0201e+02, -2.7505e+00, -3.2374e+00],\n",
       "        [-2.7773e+00,  2.7947e+00, -1.7732e-02, -5.5345e-01, -5.6602e-01,\n",
       "         -1.0838e+00,  3.9944e+02, -3.8561e+00, -5.3052e+00],\n",
       "        [-2.3225e+00, -7.2404e-01, -1.9506e-01,  4.6432e-01, -5.7760e-01,\n",
       "         -1.1935e+00,  4.0039e+02, -3.2193e+00, -4.1595e+00],\n",
       "        [-3.1766e+00,  4.2094e+00, -1.1061e-02, -1.0528e+00, -5.5708e-01,\n",
       "         -1.2905e+00,  3.9933e+02, -4.3301e+00, -6.1429e+00],\n",
       "        [-2.3558e+00, -1.3199e+00, -1.5064e-01,  6.2780e-01, -7.1959e-01,\n",
       "         -1.4375e+00,  4.0253e+02, -2.7221e+00, -2.8686e+00],\n",
       "        [-4.6050e+00,  1.2338e+00, -6.8357e-02, -1.8464e-01, -9.2678e-01,\n",
       "         -1.0374e+00,  3.9894e+02, -4.6109e+00, -6.8341e+00],\n",
       "        [-1.5027e+00,  1.2451e-01, -1.5302e-02,  6.4748e-02, -4.9750e-01,\n",
       "         -1.0348e+00,  4.0279e+02, -1.6305e+00, -1.3368e+00],\n",
       "        [-7.6214e+00,  1.7238e+00, -1.3587e-01, -2.3958e-01, -1.4602e+00,\n",
       "         -1.4616e+00,  3.9831e+02, -6.5859e+00, -1.2373e+01],\n",
       "        [-9.0209e+00, -1.2098e+00, -2.0074e-01,  5.8472e-01, -1.4599e+00,\n",
       "         -2.4418e+00,  3.9764e+02, -8.3708e+00, -1.7136e+01],\n",
       "        [-1.3895e+00,  6.7459e-01,  1.5471e-02, -1.3471e-01, -5.4067e-01,\n",
       "         -1.1295e+00,  4.0358e+02, -2.0957e+00, -3.8459e+00],\n",
       "        [-8.1522e-01,  5.6872e-01, -6.3290e-02, -1.2718e-01, -3.9052e-01,\n",
       "         -8.1474e-01,  4.0303e+02, -1.3464e+00, -1.2256e+00],\n",
       "        [-4.2575e+00, -4.5094e+00, -1.3288e-01,  9.4770e-01, -7.5762e-01,\n",
       "         -4.1437e-01,  3.9689e+02, -4.5455e+00, -8.1466e+00],\n",
       "        [-2.6961e+00, -1.5935e-01, -1.0566e-02,  2.3832e-01, -7.4489e-01,\n",
       "         -2.3313e+00,  4.0460e+02, -3.7733e+00, -7.2932e+00],\n",
       "        [-6.7466e+00, -2.8734e+00, -1.8238e-01,  6.2754e-01, -1.2443e+00,\n",
       "         -1.1927e+00,  3.9726e+02, -6.9879e+00, -1.4632e+01],\n",
       "        [-3.5642e+00, -3.6979e+00, -8.9373e-02,  7.0751e-01, -6.3986e-01,\n",
       "          1.7198e-01,  3.9589e+02, -3.6683e+00, -6.5608e+00],\n",
       "        [-3.7780e+00,  1.0057e-01,  5.6584e-02,  2.6084e-01, -1.1560e+00,\n",
       "         -3.3143e+00,  4.0682e+02, -4.5312e+00, -6.0584e+00],\n",
       "        [ 1.3044e+00, -5.2817e-01,  5.9963e-02,  6.8974e-02,  2.1434e-01,\n",
       "          1.1317e+00,  3.9538e+02, -2.4349e+00, -3.6843e+00],\n",
       "        [ 2.0082e-01, -1.8636e+00, -2.4485e-02, -2.0845e+00, -5.4710e-02,\n",
       "          8.9956e-01,  4.0698e+02,  2.6413e-01,  3.1667e-01],\n",
       "        [ 7.8115e-02, -1.9107e+00, -3.2784e-02, -1.8599e+00, -1.0155e-01,\n",
       "          8.5314e-01,  4.0752e+02,  1.7789e-01,  1.2034e-01],\n",
       "        [-6.9989e-01, -7.8495e-02, -2.0412e-02, -7.0436e-02, -1.0570e-01,\n",
       "          1.1781e+00,  3.9586e+02, -2.1561e+00, -4.0777e+00],\n",
       "        [-1.2121e-03, -1.9676e+00, -9.5486e-03, -1.4686e+00, -1.2133e-01,\n",
       "          7.1008e-01,  4.0798e+02,  1.7511e-01,  1.2377e-01],\n",
       "        [-4.2412e+00,  3.4003e-02,  7.8438e-02,  9.1854e-02, -1.1089e+00,\n",
       "         -3.6570e+00,  4.0556e+02, -5.6383e+00, -9.1489e+00],\n",
       "        [ 5.1917e-03, -1.6767e+00,  1.7461e-02, -1.7016e+00, -1.1033e-01,\n",
       "          6.8367e-01,  4.0767e+02,  5.1497e-02, -9.6329e-02],\n",
       "        [ 1.9445e-01, -1.6065e+00, -1.5901e-02, -2.2200e+00, -4.6307e-02,\n",
       "          8.1422e-01,  4.0680e+02,  2.0799e-01,  3.5863e-01],\n",
       "        [ 1.2682e-01, -1.6501e+00,  7.5817e-04, -2.5139e+00, -5.0535e-02,\n",
       "          9.1372e-01,  4.0586e+02,  1.5175e-01,  1.9031e-01],\n",
       "        [-1.8274e-02, -1.4344e+00,  1.4499e-02, -1.3816e+00, -1.2866e-01,\n",
       "          5.2272e-01,  4.0703e+02,  3.2973e-02, -2.3182e-02],\n",
       "        [ 2.1012e-01, -1.8982e+00, -3.1576e-02, -2.3195e+00, -4.0242e-02,\n",
       "          9.1119e-01,  4.0621e+02,  2.3690e-01,  3.5736e-01],\n",
       "        [-1.2215e-01, -1.1130e+00,  9.0320e-02, -1.2388e+00, -1.3728e-01,\n",
       "          3.3434e-01,  4.0646e+02, -1.8684e-01, -4.8645e-01],\n",
       "        [-1.7275e-01, -1.1315e+00,  1.1001e-01, -1.0600e+00, -1.6496e-01,\n",
       "          2.9898e-01,  4.0592e+02, -2.4860e-01, -6.8665e-01],\n",
       "        [-2.6775e+00, -7.3256e-02,  3.4796e-02,  3.6668e-01, -1.0215e+00,\n",
       "         -3.2729e+00,  4.0810e+02, -3.8550e+00, -4.2455e+00],\n",
       "        [ 6.6575e-02, -1.6490e+00, -1.9105e-02, -2.7066e+00, -7.0718e-02,\n",
       "          1.0019e+00,  4.0526e+02,  1.7713e-01,  2.0828e-01],\n",
       "        [ 1.2886e-01, -2.1127e+00, -9.6470e-02, -2.8959e+00, -6.2030e-02,\n",
       "          1.1409e+00,  4.0300e+02,  3.3079e-01,  5.5877e-01],\n",
       "        [-2.1118e+00, -4.4637e-01, -4.8895e-02,  1.2388e-01, -2.7056e-01,\n",
       "          1.0144e+00,  3.9585e+02, -2.6187e+00, -2.9048e+00],\n",
       "        [-1.8703e+00, -3.3616e-01,  1.3720e-01,  3.6649e-01, -9.0188e-01,\n",
       "         -2.7896e+00,  4.0860e+02, -2.6061e+00, -2.4775e+00],\n",
       "        [-6.0065e-01,  1.6242e-01,  3.3947e-02, -1.1946e-02, -2.5517e-02,\n",
       "          1.2560e+00,  3.9574e+02, -1.9928e+00, -2.0639e+00],\n",
       "        [-2.1028e-02, -1.4918e+00,  2.8458e-02, -7.9387e-01, -1.4253e-01,\n",
       "          4.0239e-01,  4.0474e+02,  2.7505e-02, -1.1255e-01],\n",
       "        [ 8.2671e-02, -2.2200e+00, -8.9160e-02, -2.8390e+00, -8.9131e-02,\n",
       "          1.2358e+00,  4.0336e+02,  3.7465e-01,  5.2229e-01],\n",
       "        [-2.7202e+00, -8.4523e-01, -4.9181e-02,  1.0950e-01, -3.4130e-01,\n",
       "          7.3606e-01,  3.9582e+02, -3.5368e+00, -4.0296e+00],\n",
       "        [-8.8499e-01, -3.4326e-01,  1.0867e-01,  8.1120e-01, -8.1214e-01,\n",
       "         -3.1591e+00,  4.1061e+02, -1.8757e+00, -1.3369e+00],\n",
       "        [-1.0105e-01, -9.8946e-01,  5.9893e-02, -3.3774e+00, -5.6255e-02,\n",
       "          9.3335e-01,  4.0267e+02, -1.0684e-01, -2.4159e-01],\n",
       "        [ 2.4742e-02, -1.5804e+00, -3.3180e-02, -3.2304e+00, -5.6284e-02,\n",
       "          1.0663e+00,  4.0299e+02,  1.2340e-01,  2.0876e-01],\n",
       "        [ 2.9241e-02, -1.3367e+00,  8.0088e-03, -6.4836e-01, -1.3653e-01,\n",
       "          2.7397e-01,  4.0158e+02,  1.2292e-02, -2.8927e-02],\n",
       "        [-5.3536e-01, -4.1315e-01,  3.6072e-01,  2.0129e-01, -6.4934e-01,\n",
       "         -2.4838e+00,  4.0858e+02, -1.8289e+00, -1.0958e+00],\n",
       "        [ 3.5866e-02, -2.2778e+00, -1.3578e-01, -3.0968e+00, -9.8713e-02,\n",
       "          1.2255e+00,  4.0278e+02,  3.4746e-01,  5.9890e-01],\n",
       "        [-2.0374e-01,  1.7993e-01,  6.4990e-02,  1.0175e-01, -3.2123e-01,\n",
       "         -2.0178e+00,  4.1051e+02, -3.5373e-01, -2.8084e-01],\n",
       "        [ 3.8957e-02, -1.2633e+00,  5.4250e-02, -3.5458e+00, -2.0550e-02,\n",
       "          1.0339e+00,  4.0230e+02,  1.9054e-02, -4.4831e-02],\n",
       "        [-1.3864e+00, -8.0745e-01, -3.5419e-03,  9.4051e-03, -2.2040e-01,\n",
       "          2.2283e+00,  3.9527e+02, -1.6967e+00, -2.1151e+00],\n",
       "        [ 2.1238e-01, -1.5655e+00,  1.6677e-02, -3.7125e+00,  2.8597e-03,\n",
       "          1.1033e+00,  4.0386e+02,  1.9051e-01,  3.1342e-01]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
