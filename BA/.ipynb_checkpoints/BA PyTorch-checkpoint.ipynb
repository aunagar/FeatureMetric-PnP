{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import bz2\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import autograd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"http://grail.cs.washington.edu/projects/bal/data/ladybug/\"\n",
    "FILE_NAME = \"problem-49-7776-pre.txt.bz2\"\n",
    "URL = BASE_URL + FILE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(FILE_NAME):\n",
    "    urllib.request.urlretrieve(URL, FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bal_data(file_name):\n",
    "    with bz2.open(file_name, \"rt\") as file:\n",
    "        n_cameras, n_points, n_observations = map(int, file.readline().split())\n",
    "    \n",
    "        camera_indices = np.empty(n_observations, dtype = int)\n",
    "        point_indices = np.empty(n_observations, dtype = int)\n",
    "        points_2d = torch.empty(n_observations, 2, device = device)\n",
    "\n",
    "        for i in range(n_observations):\n",
    "            camera_index, point_index, x, y = file.readline().split()\n",
    "            camera_indices[i] = camera_index\n",
    "            point_indices[i] = point_index\n",
    "            points_2d[i] = torch.tensor([float(x), float(y)])\n",
    "\n",
    "            camera_params = torch.empty(n_cameras*9, device = device, requires_grad = True)\n",
    "\n",
    "        for i in range(n_cameras*9):\n",
    "            camera_params[i] = float(file.readline())\n",
    "\n",
    "        camera_params = camera_params.view(n_cameras, -1)\n",
    "\n",
    "        points_3d = torch.empty(n_points*3, device = device, requires_grad = True)\n",
    "\n",
    "        for i in range(n_points*3):\n",
    "            points_3d[i] = float(file.readline())\n",
    "        points_3d = points_3d.view(n_points, -1)\n",
    "            \n",
    "    return camera_params, points_3d, camera_indices, point_indices, points_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_params, points_3d, camera_indices, point_indices, points_2d = read_bal_data(FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_cameras: 49\n",
      "n_points: 7776\n",
      "Total number of parameters: 23769\n",
      "Total number of residuals: 63686\n"
     ]
    }
   ],
   "source": [
    "n_cameras = camera_params.size()[0]\n",
    "n_points = points_3d.size()[0]\n",
    "\n",
    "n = 9*n_cameras + 3*n_points\n",
    "m = 2*points_2d.size()[0]\n",
    "\n",
    "print(\"n_cameras: {}\".format(n_cameras))\n",
    "print(\"n_points: {}\".format(n_points))\n",
    "print(\"Total number of parameters: {}\".format(n))\n",
    "print(\"Total number of residuals: {}\".format(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_indices = torch.tensor(camera_indices, device = device)\n",
    "point_indices = torch.tensor(point_indices, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(points, rot_vecs):\n",
    "    \n",
    "    theta = torch.norm(rot_vecs, dim = 1, keepdim=True)\n",
    "    v = rot_vecs/theta\n",
    "#         v[v != v] = 0.\n",
    "#     print(v.size(), points.size())\n",
    "    \n",
    "    dot = torch.sum(points*v, dim = 1, keepdim = True)\n",
    "    \n",
    "    cos_theta = torch.cos(theta)\n",
    "    sin_theta = torch.sin(theta)\n",
    "    \n",
    "    ans = cos_theta*points + sin_theta*torch.cross(v, points) + dot*(1-cos_theta)*v\n",
    "    \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project(points, camera_params):\n",
    "    R = torch.index_select(camera_params, 1, torch.tensor([0,1,2]))\n",
    "    T = torch.index_select(camera_params, 1, torch.tensor([3,4,5]))\n",
    "    print(R.size(), T.size())\n",
    "    points_proj = rotate(points, R)\n",
    "    points_proj = points_proj + T\n",
    "    denom = points_proj.clone()[:, 2].view(-1,1)\n",
    "    points_proj = -points_proj[:, :2]/denom\n",
    "#     f = camera_params[:,6]\n",
    "#     k1 = camera_params[:,7]\n",
    "#     k2 = camera_params[:,8]\n",
    "    f = torch.index_select(camera_params, 1, torch.tensor([6]))\n",
    "    k1 = torch.index_select(camera_params, 1, torch.tensor([7]))\n",
    "    k2 = torch.index_select(camera_params, 1, torch.tensor([8]))\n",
    "    \n",
    "    n = torch.sum(points_proj**2, dim = 1)\n",
    "    r = 1 + n*k1 + k2*n**2\n",
    "    points_proj = points_proj*(r*f).view(-1,1)\n",
    "    return points_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(camera_params, points_3d, n_cameras, n_points, camera_indices, point_indices, points_2d):\n",
    "#     cp = params[:n_cameras*9].view(n_cameras, 9)\n",
    "#     p3d = params[n_cameras*9:].view(n_points, 3)\n",
    "#     points_proj = project(p3d[point_indices], cp[camera_indices])\n",
    "    points_3d_2 = torch.index_select(points_3d, 0, point_indices)\n",
    "    camera_params_2 = torch.index_select(camera_params, 0, camera_indices)\n",
    "    points_proj = project(points_3d_2, camera_params_2)\n",
    "    ans = points_proj - points_2d\n",
    "    return ans.view(ans.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31843, 3]) torch.Size([31843, 3])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 4055906596 bytes. Error code 12 (Cannot allocate memory)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-2948557c8fc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcamera_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints_3d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cameras\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcamera_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoint_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints_2d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-826d0fad6d6b>\u001b[0m in \u001b[0;36mfun\u001b[0;34m(camera_params, points_3d, n_cameras, n_points, camera_indices, point_indices, points_2d)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpoints_3d_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints_3d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoint_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcamera_params_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcamera_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcamera_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mpoints_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints_3d_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcamera_params_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoints_proj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpoints_2d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-70f4498c5c1a>\u001b[0m in \u001b[0;36mproject\u001b[0;34m(points, camera_params)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints_proj\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mk1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mpoints_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoints_proj\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpoints_proj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 4055906596 bytes. Error code 12 (Cannot allocate memory)\n"
     ]
    }
   ],
   "source": [
    "f0 = fun(camera_params, points_3d, n_cameras, n_points, camera_indices, point_indices, points_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31843, 3]) torch.Size([31843, 3])\n",
      "torch.Size([31843, 1])\n",
      "torch.Size([31843])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 4055906596 bytes. Error code 12 (Cannot allocate memory)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-54598957eb0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcamera_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints_3d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cameras\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcamera_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoint_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints_2d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-498338d024f0>\u001b[0m in \u001b[0;36mfun\u001b[0;34m(camera_params, points_3d, n_cameras, n_points, camera_indices, point_indices, points_2d)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpoints_3d_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints_3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoint_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcamera_params_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcamera_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcamera_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mpoints_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints_3d_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcamera_params_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoints_proj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpoints_2d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-dba22b2fc717>\u001b[0m in \u001b[0;36mproject\u001b[0;34m(points, camera_params)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mk1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mpoints_proj_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoints_proj_2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpoints_proj_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 4055906596 bytes. Error code 12 (Cannot allocate memory)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    f = fun(camera_params, points_3d, n_cameras, n_points, camera_indices, point_indices, points_2d)\n",
    "    \n",
    "    loss = f.pow(2).sum()\n",
    "    \n",
    "    print(i, \" --> \", loss.item())\n",
    "    loss.backward()\n",
    "\n",
    "    \n",
    "    with autograd.detect_anomaly():\n",
    "        camera_params -= lr*camera_params.grad\n",
    "        points_3d -= lr*points_3d.grad\n",
    "        \n",
    "        camera_params.grad.zero_()\n",
    "        points_3d.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7fe5caad0650>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6120,  0.5718, -1.8471],\n",
       "        [-0.6120,  0.5718, -1.8471],\n",
       "        [-0.6120,  0.5718, -1.8471],\n",
       "        ...,\n",
       "        [-0.8193,  0.0765, -4.5143],\n",
       "        [-0.7480,  0.0371, -4.8132],\n",
       "        [-0.7480,  0.0371, -4.8132]], grad_fn=<IndexSelectBackward>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.index_select(points_3d, 0, torch.tensor(point_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
