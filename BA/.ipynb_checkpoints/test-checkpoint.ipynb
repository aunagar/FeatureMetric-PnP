{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from featureBA.src.model import sparse3DBA\n",
    "from featureBA.src.utils import sobel_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open(\"toy_example/data/toyexample_1_data.p\", 'rb'))\n",
    "img = cv2.imread(\"toy_example/data/toyexample_1.png\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_perturbed = np.array([[math.cos(5*math.pi/180), -math.sin(5*math.pi/180), 0, 0],\n",
    "             [math.sin(5*math.pi/180), math.cos(5*math.pi/180), 0, 0],\n",
    "             [0, 0, 1, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['coords'] = np.around(data['2d_points']).astype(int) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_perturbed = np.dot(data['K'], T_perturbed)\n",
    "projected_2d = np.dot(P_perturbed, np.concatenate((data['3d_points'], np.ones(len(data['3d_points']))[:, None]),-1).T)\n",
    "projected_2d = (projected_2d.T/projected_2d.T[:,2,None])[:, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_2d = np.around(projected_2d)\n",
    "coords_2d = coords_2d.astype(int) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 55 104]\n",
      "1 [85 74]\n",
      "2 [ 30 107]\n",
      "3 [41 71]\n",
      "4 [79 50]\n",
      "5 [119  47]\n",
      "6 [85 89]\n",
      "7 [62 85]\n",
      "8 [ 76 111]\n",
      "9 [57 53]\n",
      "10 [70 99]\n",
      "11 [ 97 115]\n",
      "12 [97 48]\n",
      "13 [ 73 119]\n"
     ]
    }
   ],
   "source": [
    "img = img.astype('uint8')\n",
    "for i, p in enumerate(data['coords']):\n",
    "    print(i, p)\n",
    "    cv2.circle(img, tuple(p), 1, (128, 128, 0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run BA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from featureBA.src.model import sparse3DBA\n",
    "from featureBA.src.utils import sobel_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"toy_example/toyexample_1.png\", 0)\n",
    "img = img.astype('double')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_torch = torch.from_numpy(img)[None,...]\n",
    "grad_x, grad_y = sobel_filter(img_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image', grad_y.numpy().reshape(img.shape))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts3D = torch.from_numpy(np.delete(data['3d_points'], 6, 0)[:,:3])\n",
    "ref2d = torch.from_numpy(np.flip(data['2d_coords']).copy())\n",
    "feature_ref = torch.cat([img_torch[:, i, j].unsqueeze(0) for i, j in zip(ref2d[:,0], ref2d[:,1])]).type(torch.DoubleTensor)\n",
    "feature_map_query = img_torch.type(torch.DoubleTensor)\n",
    "R_init, t_init = torch.from_numpy(T_perturbed[:, :3]), torch.from_numpy(T_perturbed[:, 3])\n",
    "feature_grad_x = grad_x\n",
    "feature_grad_y = grad_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3dba = sparse3DBA(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R, t = s3dba(pts3D, feature_ref, feature_map_query, grad_x, grad_y, data['K'], R_init, t_init)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
